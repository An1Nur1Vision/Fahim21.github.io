<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Your Name</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0 auto;
            padding: 20px;
            max-width: 800px;
            background-color: #f0f0f0;
            color: #333;
        }
        h1 {
            text-align: center;
            color: #333;
        }
        h2 {
            color: #333;
            margin-top: 2em;
        }
        hr {
            border: 0;
            border-top: 1px solid #ccc;
            margin: 2em 0;
        }
        p, ul {
            margin: 1em 0;
        }
        ul {
            list-style-type: disc;
            margin-left: 2em;
        }
        a {
            color: #0066cc;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 1em auto;
            border: 1px solid #ccc;
        }
    </style>
</head>
<body>
    <h1>Your Name</h1>
    <p style="text-align: center;">
        [Your Position, e.g., PhD Student] at [Your Institution, e.g., University of Example]
    </p>

    <hr>

    <h2>About</h2>
    <p>
        I am a researcher in computer vision and generative AI, with a focus on diffusion-based style transfer. My work explores efficient, zero-shot methods for image and video stylization, drawing inspiration from artistic workflows. I am currently [your position] at [your institution], advised by [advisor, if applicable].
    </p>

    <hr>

    <h2>Publications</h2>
    <ul>
        <li>
            <strong>Enabling Artistâ€™s Template for Zero-shot Style Transfer with Diffusion Models</strong><br>
            [Your Name], [Co-authors, if any]<br>
            Under submission, 2025<br>
            <a href="papers/style_transfer_paper.pdf">PDF</a> | <a href="https://github.com/username/style-transfer">Code</a>
        </li>
    </ul>
    <p>
        <strong>Abstract</strong>: Diffusion models excel in text-to-image generation and are advancing zero-shot visual tasks like style transfer. Traditional diffusion-based style transfer relies on self-attention swapping, which struggles to balance content preservation with style injection and prompt alignment. We propose an efficient framework to address these challenges: (1) a novel template-guided mechanism, using a blended content-style latent to enhance attention interactions for both images and videos with spatio-temporal coherence, and (2) a zero-cost attention modulation strategy that optimizes self- and cross-attention components. Our approach delivers superior stylization, ensuring robust content fidelity and style consistency in zero-shot settings. Evaluations demonstrate that our method surpasses state-of-the-art approaches across diverse benchmarks.
    </p>
    <p>
        <strong>Qualitative Results</strong>: The figure below compares our method against state-of-the-art approaches for image and video stylization.
    </p>
    <img src="images/comp_template11.png" alt="Qualitative comparison of style transfer methods">

    <hr>

    <h2>Contact</h2>
    <p>
        <strong>Email</strong>: <a href="mailto:your.email@example.com">your.email@example.com</a><br>
        <strong>GitHub</strong>: <a href="https://github.com/username">github.com/username</a><br>
        <strong>Google Scholar</strong>: <a href="https://scholar.google.com/citations?user=your_id">Google Scholar Profile</a>
    </p>
</body>
</html>
